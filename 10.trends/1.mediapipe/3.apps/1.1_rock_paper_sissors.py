
import cv2
import mediapipe as mp

# MediaPipe hands ì´ˆê¸°í™”
mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils

hands = mp_hands.Hands(
    max_num_hands=1,
    min_detection_confidence=0.7,
    min_tracking_confidence=0.5
)

# ì†ê°€ë½ ì¸ë±ìŠ¤: 4(ì—„ì§€), 8(ê²€ì§€), 12(ì¤‘ì§€), 16(ì•½ì§€), 20(ìƒˆë¼)
FINGER_TIPS = [4, 8, 12, 16, 20]

# ì†ê°€ë½ ìƒíƒœ íŒë‹¨ í•¨ìˆ˜ (True: í´ì§, False: ì ‘í˜)
def get_finger_states(hand_landmarks):
    finger_states = []

    # ì—„ì§€: xì¢Œí‘œ ë¹„êµ
    thumb_tip = hand_landmarks.landmark[4]
    thumb_ip = hand_landmarks.landmark[3]
    finger_states.append(thumb_tip.x < thumb_ip.x)  # ì˜¤ë¥¸ì† ê¸°ì¤€

    # ë‚˜ë¨¸ì§€ ì†ê°€ë½: tipì´ pipë³´ë‹¤ ìœ„ì— ìˆëŠ”ì§€(yì¢Œí‘œê°€ ì‘ìŒ)
    for tip_id in FINGER_TIPS[1:]:
        tip = hand_landmarks.landmark[tip_id]
        pip = hand_landmarks.landmark[tip_id - 2]
        finger_states.append(tip.y < pip.y)

    return finger_states  # [ì—„ì§€, ê²€ì§€, ì¤‘ì§€, ì•½ì§€, ìƒˆë¼]

# ì† ëª¨ì–‘ íŒë³„
def classify_hand(finger_states):
    if finger_states == [False, False, False, False, False]:
        return "ë°”ìœ„" # âœŠ
    elif finger_states == [False, True, True, False, False]:
        return "ê°€ìœ„" # âœŒï¸
    elif finger_states == [True, True, True, True, True]:
        return "ë³´" # âœ‹
    else:
        return "íŒë³„ë¶ˆê°€" # ğŸ¤”


# í•œê¸€ ì¶œë ¥ìš© -->
from PIL import ImageFont, ImageDraw, Image
import numpy as np

# í•œê¸€ ê¸€ê¼´ ê²½ë¡œ (Windows ê¸°ì¤€: ë§‘ì€ê³ ë”•)
FONT_PATH = "C:/Windows/Fonts/malgun.ttf"  # ë˜ëŠ” ì›í•˜ëŠ” .ttf ê²½ë¡œ
FONT_SIZE = 40
font = ImageFont.truetype(FONT_PATH, FONT_SIZE)

# PILë¡œ í•œê¸€ì„ ì´ë¯¸ì§€ì— ê·¸ë¦¬ê¸°
def draw_text_pil(img, text, position=(10, 50), color=(0, 255, 0)):
    # OpenCV â†’ PIL ì´ë¯¸ì§€ ë³€í™˜
    img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img_pil)
    draw.text(position, text, font=font, fill=color)
    # PIL â†’ OpenCV ì´ë¯¸ì§€ ë³€í™˜
    return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)

# í•œê¸€ ì¶œë ¥ìš© <--


# ì›¹ìº  ì‹¤í–‰
cap = cv2.VideoCapture(0)

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # ì¢Œìš° ë°˜ì „ ë° RGB ë³€í™˜
    frame = cv2.flip(frame, 1)
    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    results = hands.process(rgb)

    if results.multi_hand_landmarks:
        for hand_landmarks in results.multi_hand_landmarks:
            # ì†ê°€ë½ ìƒíƒœ ë¶„ì„ ë° ê²°ê³¼ í‘œì‹œ
            finger_states = get_finger_states(hand_landmarks)
            gesture = classify_hand(finger_states)

            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)
            # cv2.putText(frame, gesture, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 3, cv2.LINE_AA)
            frame = draw_text_pil(frame, gesture, position=(10, 50), color=(0, 255, 0))

    cv2.imshow("ê°€ìœ„ ë°”ìœ„ ë³´ ì¸ì‹ê¸°", frame)
    if cv2.waitKey(1) & 0xFF == 27:  # ESC í‚¤ ì¢…ë£Œ
        break

cap.release()
cv2.destroyAllWindows()
